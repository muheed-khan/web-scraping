{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/muheedahmedkhan/web-scraping-using-scrapy?scriptVersionId=193282325\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"c273bfc0","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:12.02026Z","iopub.status.busy":"2024-08-20T08:35:12.01984Z","iopub.status.idle":"2024-08-20T08:35:37.585156Z","shell.execute_reply":"2024-08-20T08:35:37.583697Z"},"papermill":{"duration":25.580075,"end_time":"2024-08-20T08:35:37.58813","exception":false,"start_time":"2024-08-20T08:35:12.008055","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scrapy\r\n","  Downloading Scrapy-2.11.2-py2.py3-none-any.whl.metadata (5.3 kB)\r\n","Collecting Twisted>=18.9.0 (from scrapy)\r\n","  Downloading twisted-24.7.0-py3-none-any.whl.metadata (18 kB)\r\n","Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from scrapy) (41.0.7)\r\n","Collecting cssselect>=0.9.1 (from scrapy)\r\n","  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\r\n","Collecting itemloaders>=1.0.1 (from scrapy)\r\n","  Downloading itemloaders-1.3.1-py3-none-any.whl.metadata (3.9 kB)\r\n","Collecting parsel>=1.5.0 (from scrapy)\r\n","  Downloading parsel-1.9.1-py2.py3-none-any.whl.metadata (11 kB)\r\n","Requirement already satisfied: pyOpenSSL>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from scrapy) (23.3.0)\r\n","Collecting queuelib>=1.4.2 (from scrapy)\r\n","  Downloading queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\r\n","Collecting service-identity>=18.1.0 (from scrapy)\r\n","  Downloading service_identity-24.1.0-py3-none-any.whl.metadata (4.8 kB)\r\n","Collecting w3lib>=1.17.0 (from scrapy)\r\n","  Downloading w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\r\n","Collecting zope.interface>=5.1.0 (from scrapy)\r\n","  Downloading zope.interface-7.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m770.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\r\n","  Downloading Protego-0.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\r\n","Collecting itemadapter>=0.1.0 (from scrapy)\r\n","  Downloading itemadapter-0.9.0-py3-none-any.whl.metadata (17 kB)\r\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from scrapy) (69.0.3)\r\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from scrapy) (21.3)\r\n","Collecting tldextract (from scrapy)\r\n","  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\r\n","Requirement already satisfied: lxml>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from scrapy) (5.2.2)\r\n","Requirement already satisfied: defusedxml>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from scrapy) (0.7.1)\r\n","Collecting PyDispatcher>=2.0.5 (from scrapy)\r\n","  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\r\n","Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\r\n","Requirement already satisfied: jmespath>=0.9.5 in /opt/conda/lib/python3.10/site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\r\n","Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (23.2.0)\r\n","Requirement already satisfied: pyasn1 in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (0.5.1)\r\n","Requirement already satisfied: pyasn1-modules in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\r\n","Collecting automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\r\n","  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\r\n","Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\r\n","  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\r\n","Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\r\n","  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\r\n","Collecting incremental>=24.7.0 (from Twisted>=18.9.0->scrapy)\r\n","  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\r\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (4.9.0)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->scrapy) (3.1.1)\r\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from tldextract->scrapy) (3.6)\r\n","Requirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from tldextract->scrapy) (2.32.3)\r\n","Collecting requests-file>=1.4 (from tldextract->scrapy)\r\n","  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n","Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.10/site-packages (from tldextract->scrapy) (3.13.1)\r\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\r\n","Requirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from incremental>=24.7.0->Twisted>=18.9.0->scrapy) (2.0.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.2.2)\r\n","Downloading Scrapy-2.11.2-py2.py3-none-any.whl (290 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\r\n","Downloading itemadapter-0.9.0-py3-none-any.whl (11 kB)\r\n","Downloading itemloaders-1.3.1-py3-none-any.whl (12 kB)\r\n","Downloading parsel-1.9.1-py2.py3-none-any.whl (17 kB)\r\n","Downloading Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)\r\n","Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\r\n","Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\r\n","Downloading service_identity-24.1.0-py3-none-any.whl (12 kB)\r\n","Downloading twisted-24.7.0-py3-none-any.whl (3.2 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading w3lib-2.2.1-py3-none-any.whl (21 kB)\r\n","Downloading zope.interface-7.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\r\n","Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\r\n","Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\r\n","Installing collected packages: PyDispatcher, zope.interface, w3lib, queuelib, protego, itemadapter, incremental, hyperlink, cssselect, constantly, automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy\r\n","Successfully installed PyDispatcher-2.0.7 Twisted-24.7.0 automat-24.8.1 constantly-23.10.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.9.0 itemloaders-1.3.1 parsel-1.9.1 protego-0.3.1 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.11.2 service-identity-24.1.0 tldextract-5.1.2 w3lib-2.2.1 zope.interface-7.0.1\r\n"]}],"source":["!pip install scrapy"]},{"cell_type":"code","execution_count":2,"id":"fd43070c","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:37.616154Z","iopub.status.busy":"2024-08-20T08:35:37.615713Z","iopub.status.idle":"2024-08-20T08:35:38.335478Z","shell.execute_reply":"2024-08-20T08:35:38.334225Z"},"papermill":{"duration":0.737084,"end_time":"2024-08-20T08:35:38.338355","exception":false,"start_time":"2024-08-20T08:35:37.601271","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scrapy/utils/_compression.py:15: ScrapyDeprecationWarning: You have brotlipy installed, and Scrapy will use it, but Scrapy support for brotlipy is deprecated and will stop working in a future version of Scrapy. brotlipy itself is deprecated, it has been superseded by brotlicffi (not currently supported by Scrapy). Please, uninstall brotlipy and install brotli instead. brotlipy has the same import name as brotli, so keeping both installed is strongly discouraged.\n","  warn(\n"]}],"source":["from scrapy import Selector"]},{"cell_type":"code","execution_count":3,"id":"5444f33f","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.367604Z","iopub.status.busy":"2024-08-20T08:35:38.366437Z","iopub.status.idle":"2024-08-20T08:35:38.372544Z","shell.execute_reply":"2024-08-20T08:35:38.371287Z"},"papermill":{"duration":0.023325,"end_time":"2024-08-20T08:35:38.375108","exception":false,"start_time":"2024-08-20T08:35:38.351783","status":"completed"},"tags":[]},"outputs":[],"source":["html = '''\n","<html>\n","<body>\n","\n","         <div class=\"hello datacamp\">\n","         <p>Hello World!</p>\n","         <p>Enjoy DataCamp!</p>\n","         </div>\n","         \n","\n","</body>\n","</html>\n","'''"]},{"cell_type":"code","execution_count":4,"id":"a7e58cab","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.402993Z","iopub.status.busy":"2024-08-20T08:35:38.402595Z","iopub.status.idle":"2024-08-20T08:35:38.410861Z","shell.execute_reply":"2024-08-20T08:35:38.409609Z"},"papermill":{"duration":0.025328,"end_time":"2024-08-20T08:35:38.413456","exception":false,"start_time":"2024-08-20T08:35:38.388128","status":"completed"},"tags":[]},"outputs":[],"source":["sel = Selector(text = html)"]},{"cell_type":"code","execution_count":5,"id":"49270007","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.442362Z","iopub.status.busy":"2024-08-20T08:35:38.441985Z","iopub.status.idle":"2024-08-20T08:35:38.451589Z","shell.execute_reply":"2024-08-20T08:35:38.450507Z"},"papermill":{"duration":0.027087,"end_time":"2024-08-20T08:35:38.454041","exception":false,"start_time":"2024-08-20T08:35:38.426954","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[<Selector query='/html/body/div/p' data='<p>Hello World!</p>'>,\n"," <Selector query='/html/body/div/p' data='<p>Enjoy DataCamp!</p>'>]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["xpath = '/html/body/div/p'\n","sel.xpath(xpath)"]},{"cell_type":"code","execution_count":6,"id":"5b047d3a","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.481912Z","iopub.status.busy":"2024-08-20T08:35:38.481495Z","iopub.status.idle":"2024-08-20T08:35:38.489024Z","shell.execute_reply":"2024-08-20T08:35:38.487839Z"},"papermill":{"duration":0.024409,"end_time":"2024-08-20T08:35:38.49167","exception":false,"start_time":"2024-08-20T08:35:38.467261","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["['<p>Hello World!</p>', '<p>Enjoy DataCamp!</p>']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["sel.xpath(xpath).extract()"]},{"cell_type":"code","execution_count":7,"id":"383607f6","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.520202Z","iopub.status.busy":"2024-08-20T08:35:38.519815Z","iopub.status.idle":"2024-08-20T08:35:38.527505Z","shell.execute_reply":"2024-08-20T08:35:38.526365Z"},"papermill":{"duration":0.024992,"end_time":"2024-08-20T08:35:38.530104","exception":false,"start_time":"2024-08-20T08:35:38.505112","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'<p>Hello World!</p>'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sel.xpath(xpath).extract_first()"]},{"cell_type":"markdown","id":"7be1c903","metadata":{"papermill":{"duration":0.013146,"end_time":"2024-08-20T08:35:38.557151","exception":false,"start_time":"2024-08-20T08:35:38.544005","status":"completed"},"tags":[]},"source":["another way to do the same ting done above"]},{"cell_type":"code","execution_count":8,"id":"c3a03ba7","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.587081Z","iopub.status.busy":"2024-08-20T08:35:38.586669Z","iopub.status.idle":"2024-08-20T08:35:38.594106Z","shell.execute_reply":"2024-08-20T08:35:38.593033Z"},"papermill":{"duration":0.025739,"end_time":"2024-08-20T08:35:38.597038","exception":false,"start_time":"2024-08-20T08:35:38.571299","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'<p>Hello World!</p>'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ps = sel.xpath('//p')\n","first_p = ps[0]\n","first_p.extract()"]},{"cell_type":"markdown","id":"9bfb2598","metadata":{"papermill":{"duration":0.013237,"end_time":"2024-08-20T08:35:38.624038","exception":false,"start_time":"2024-08-20T08:35:38.610801","status":"completed"},"tags":[]},"source":["Request to get the web pages"]},{"cell_type":"code","execution_count":9,"id":"9cb0873a","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.652699Z","iopub.status.busy":"2024-08-20T08:35:38.652265Z","iopub.status.idle":"2024-08-20T08:35:38.917287Z","shell.execute_reply":"2024-08-20T08:35:38.915402Z"},"papermill":{"duration":0.28283,"end_time":"2024-08-20T08:35:38.920259","exception":false,"start_time":"2024-08-20T08:35:38.637429","status":"completed"},"tags":[]},"outputs":[],"source":["import requests\n","url = 'https://en.wikipedia.org/wiki/Web_scraping'\n","html = requests.get(url).content\n","sel = Selector(text = html)"]},{"cell_type":"code","execution_count":10,"id":"48618b6f","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.949933Z","iopub.status.busy":"2024-08-20T08:35:38.949496Z","iopub.status.idle":"2024-08-20T08:35:38.959129Z","shell.execute_reply":"2024-08-20T08:35:38.958049Z"},"papermill":{"duration":0.0271,"end_time":"2024-08-20T08:35:38.96167","exception":false,"start_time":"2024-08-20T08:35:38.93457","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[<Selector query='//p' data='<p><b>Web scraping</b>, <b>web harves...'>,\n"," <Selector query='//p' data='<p>Scraping a web page involves fetch...'>,\n"," <Selector query='//p' data='<p>As well as <a href=\"/wiki/Contact_...'>,\n"," <Selector query='//p' data='<p><a href=\"/wiki/Web_page\" title=\"We...'>,\n"," <Selector query='//p' data='<p>Newer forms of web scraping involv...'>]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#first 5 p elements\n","xpath = '//p'\n","selected_text = sel.xpath(xpath)\n","selected_text = selected_text[:5]\n","selected_text"]},{"cell_type":"code","execution_count":11,"id":"7a49d552","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:38.991201Z","iopub.status.busy":"2024-08-20T08:35:38.990799Z","iopub.status.idle":"2024-08-20T08:35:38.998827Z","shell.execute_reply":"2024-08-20T08:35:38.997626Z"},"papermill":{"duration":0.025736,"end_time":"2024-08-20T08:35:39.001376","exception":false,"start_time":"2024-08-20T08:35:38.97564","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'<p><b>Web scraping</b>, <b>web harvesting</b>, or <b>web data extraction</b> is <a href=\"/wiki/Data_scraping\" title=\"Data scraping\">data scraping</a> used for <a href=\"/wiki/Data_extraction\" title=\"Data extraction\">extracting data</a> from <a href=\"/wiki/Website\" title=\"Website\">websites</a>.<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\"><span class=\"cite-bracket\">[</span>1<span class=\"cite-bracket\">]</span></a></sup> Web scraping software may directly access the <a href=\"/wiki/World_Wide_Web\" title=\"World Wide Web\">World Wide Web</a> using the <a href=\"/wiki/Hypertext_Transfer_Protocol\" class=\"mw-redirect\" title=\"Hypertext Transfer Protocol\">Hypertext Transfer Protocol</a> or a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a <a href=\"/wiki/Internet_bot\" title=\"Internet bot\">bot</a> or <a href=\"/wiki/Web_crawler\" title=\"Web crawler\">web crawler</a>. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local <a href=\"/wiki/Database\" title=\"Database\">database</a> or spreadsheet, for later <a href=\"/wiki/Data_retrieval\" title=\"Data retrieval\">retrieval</a> or <a href=\"/wiki/Data_analysis\" title=\"Data analysis\">analysis</a>.\\n</p>'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["selected_text[0].extract()"]},{"cell_type":"markdown","id":"a88a3850","metadata":{"papermill":{"duration":0.013508,"end_time":"2024-08-20T08:35:39.028612","exception":false,"start_time":"2024-08-20T08:35:39.015104","status":"completed"},"tags":[]},"source":["top 5 p tags using cssLocator"]},{"cell_type":"code","execution_count":12,"id":"ddeaad64","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:39.058037Z","iopub.status.busy":"2024-08-20T08:35:39.057599Z","iopub.status.idle":"2024-08-20T08:35:39.067227Z","shell.execute_reply":"2024-08-20T08:35:39.066174Z"},"papermill":{"duration":0.02731,"end_time":"2024-08-20T08:35:39.069732","exception":false,"start_time":"2024-08-20T08:35:39.042422","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[<Selector query='descendant-or-self::p' data='<p><b>Web scraping</b>, <b>web harves...'>,\n"," <Selector query='descendant-or-self::p' data='<p>Scraping a web page involves fetch...'>,\n"," <Selector query='descendant-or-self::p' data='<p>As well as <a href=\"/wiki/Contact_...'>,\n"," <Selector query='descendant-or-self::p' data='<p><a href=\"/wiki/Web_page\" title=\"We...'>,\n"," <Selector query='descendant-or-self::p' data='<p>Newer forms of web scraping involv...'>]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["cssLocator = 'p'\n","p_tags_using_css_locator = sel.css(cssLocator)\n","p_tags_using_css_locator = p_tags_using_css_locator[:5]\n","p_tags_using_css_locator"]},{"cell_type":"code","execution_count":13,"id":"78a3ac73","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:39.099821Z","iopub.status.busy":"2024-08-20T08:35:39.099391Z","iopub.status.idle":"2024-08-20T08:35:39.107153Z","shell.execute_reply":"2024-08-20T08:35:39.105781Z"},"papermill":{"duration":0.026006,"end_time":"2024-08-20T08:35:39.109658","exception":false,"start_time":"2024-08-20T08:35:39.083652","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'<p>Scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, extraction can take place. The content of a page may be <a href=\"/wiki/Parsing\" title=\"Parsing\">parsed</a>, searched and reformatted, and its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be finding and copying names and telephone numbers, companies and their URLs, or e-mail addresses to a list (contact scraping).\\n</p>'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["p_tags_using_css_locator[1].extract()"]},{"cell_type":"markdown","id":"b5b74285","metadata":{"papermill":{"duration":0.014363,"end_time":"2024-08-20T08:35:39.13822","exception":false,"start_time":"2024-08-20T08:35:39.123857","status":"completed"},"tags":[]},"source":["Applying web-scrapping on pakwheels"]},{"cell_type":"code","execution_count":14,"id":"1c7a88a0","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:39.168463Z","iopub.status.busy":"2024-08-20T08:35:39.16801Z","iopub.status.idle":"2024-08-20T08:35:40.13697Z","shell.execute_reply":"2024-08-20T08:35:40.134627Z"},"papermill":{"duration":0.98727,"end_time":"2024-08-20T08:35:40.139772","exception":false,"start_time":"2024-08-20T08:35:39.152502","status":"completed"},"tags":[]},"outputs":[],"source":["import requests\n","url = 'https://www.pakwheels.com/used-cars/automatic/57336'\n","html = requests.get(url).content\n","sel = Selector(text = html)"]},{"cell_type":"code","execution_count":15,"id":"5c182d7f","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:40.170503Z","iopub.status.busy":"2024-08-20T08:35:40.170064Z","iopub.status.idle":"2024-08-20T08:35:40.184327Z","shell.execute_reply":"2024-08-20T08:35:40.182975Z"},"papermill":{"duration":0.033268,"end_time":"2024-08-20T08:35:40.187256","exception":false,"start_time":"2024-08-20T08:35:40.153988","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["cssLocator = 'ul.list-unstyled.search-results li div.col-md-9.grid-style div a h3::text'\n","car_titles = sel.css(cssLocator).getall()"]},{"cell_type":"code","execution_count":16,"id":"de1ec765","metadata":{"execution":{"iopub.execute_input":"2024-08-20T08:35:40.218645Z","iopub.status.busy":"2024-08-20T08:35:40.218158Z","iopub.status.idle":"2024-08-20T08:35:40.225741Z","shell.execute_reply":"2024-08-20T08:35:40.224605Z"},"papermill":{"duration":0.026299,"end_time":"2024-08-20T08:35:40.228275","exception":false,"start_time":"2024-08-20T08:35:40.201976","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["['Toyota Corolla  2018 Altis Grande CVT-i 1.8 for Sale',\n"," 'BMW 7 Series  2002 745i for Sale',\n"," 'Suzuki Every 11th Generation (JDM) 2015 GA for Sale',\n"," 'Toyota Prado 90 Series 1996 TZ 3.0D for Sale',\n"," 'Toyota Prado  1991  for Sale',\n"," 'Toyota C-HR  2017 S-GR Package for Sale',\n"," 'Honda Insight  2019 EX for Sale',\n"," 'Toyota Surf  1992  for Sale',\n"," 'Suzuki Alto  2023 Hybrid X for Sale',\n"," 'Toyota Hilux  2020 Revo V Automatic 2.8 for Sale',\n"," 'Toyota Corolla Cross  2024 1.8 HEV X for Sale',\n"," 'Toyota Corolla Fielder  2006 S 202 for Sale',\n"," 'Toyota Prius  2011 S 1.8 for Sale',\n"," 'Suzuki Wagon R  2013 Stingray T for Sale',\n"," 'Nissan Dayz Highway Star  2013  for Sale',\n"," 'Toyota Fortuner  2018 2.7 VVTi for Sale',\n"," 'Honda Civic  2019 Oriel 1.8 i-VTEC CVT for Sale',\n"," 'Honda Civic  2019 Oriel 1.8 i-VTEC CVT for Sale',\n"," 'Toyota Hilux  2016 Vigo Champ GX for Sale',\n"," 'Toyota Prado 90 Series 2002 TX Limited 2.7 for Sale',\n"," 'Toyota Fortuner  2022 Legender  for Sale',\n"," 'Toyota Crown  1973  for Sale',\n"," 'Toyota Fortuner  2022 Legender  for Sale',\n"," 'Toyota Yaris Hatchback  2021  for Sale',\n"," 'KIA Sportage  2024 AWD for Sale']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["car_titles"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":31.996898,"end_time":"2024-08-20T08:35:40.764808","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-08-20T08:35:08.76791","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}